[{"path":"/articles/dichotomous.html","id":"description-of-data-example","dir":"Articles","previous_headings":"","what":"Description of data example","title":"Agreement for dichotomous outcomes","text":"data example used data study Dikmans et al. (2017). data based photographs breasts 50 women breast reconstruction. photographs independently scored 5 surgeons, patient, three mothers. rated quality reconstruction 5 point ordinal scale verbal anchors left side ‘dissatisfied’ left end right end ‘satisfied’ right end. specifically rated volume, shape, symmetry, scars nipple. paper use data 4 surgeons one surgeon missing values look rates symmetry. satisfaction scores dichotomised satisfied (scores 4 5) satisfied (scores 1,2, 3).","code":"data(breast) variable <- \"symmetry\" raters <- c(\"PCH1\", \"PCH2\", \"PCH3\", \"PCH4\") ratersvars <- paste(raters, variable, sep=\"_\") data1 <- data.frame(breast[ratersvars])  for (r in 1:length(ratersvars)){     data1[ratersvars[r]] <- ifelse(data1[ratersvars[r]]==\"very satisfied\"|data1[ratersvars[r]]==\"satisfied\",\"satisfied\",\"not satisfied\")  } data1 <- data.frame(apply(data1[ratersvars], 2, as.factor), stringsAsFactors = TRUE)  head(data1) ##   PCH1_symmetry PCH2_symmetry PCH3_symmetry PCH4_symmetry ## 1     satisfied     satisfied     satisfied     satisfied ## 2 not satisfied not satisfied not satisfied not satisfied ## 3     satisfied not satisfied not satisfied not satisfied ## 4 not satisfied not satisfied not satisfied not satisfied ## 5 not satisfied     satisfied not satisfied     satisfied ## 6     satisfied not satisfied     satisfied     satisfied"},{"path":"/articles/dichotomous.html","id":"agreement-table","dir":"Articles","previous_headings":"Description of data example","what":"Agreement table","title":"Agreement for dichotomous outcomes","text":"First agreement tables summed rater combinations one agreement table. diagonal cells averaged obtain symmetry agreement tables. Note data1 contains column per rater variable interest.","code":"sumtable(data1,offdiag = FALSE) %>% kable() sumtable(data1,offdiag = TRUE) %>% kable()"},{"path":"/articles/dichotomous.html","id":"agreement","dir":"Articles","previous_headings":"Description of data example","what":"Agreement","title":"Agreement for dichotomous outcomes","text":"agreement table can calculate agreement. can calculate confidence interval around agreement.","code":"agreement(data1) ## overall agreement  ##         0.7466667 agreement(data1, confint = TRUE) ## overall agreement             lower             upper  ##         0.7466667         0.6608408         0.8215369"},{"path":"/articles/dichotomous.html","id":"specific-agreement","dir":"Articles","previous_headings":"Description of data example","what":"Specific agreement","title":"Agreement for dichotomous outcomes","text":"specific agreement dichotomous data can evaluated satisfied scores satisfied scores.","code":"agreement(data1, specific=\"satisfied\", confint = TRUE) ##                                       p     lower     upper ## overall agreement             0.7466667 0.6608408 0.8215369 ## specific agreement: satisfied 0.7564103 0.6407977 0.8505168 agreement(data1, specific=\"not satisfied\", confint = TRUE) ##                                           p     lower     upper ## overall agreement                 0.7466667 0.6608408 0.8215369 ## specific agreement: not satisfied 0.7361111 0.6156558 0.8355576"},{"path":"/articles/dichotomous.html","id":"validation-of-confidence-interval","dir":"Articles","previous_headings":"Description of data example","what":"Validation of Confidence interval","title":"Agreement for dichotomous outcomes","text":"Simulation compare Fleis correction Follows….","code":""},{"path":[]},{"path":[]},{"path":"/articles/icc_varcomp.html","id":"breast","dir":"Articles","previous_headings":"Data example","what":"Breast","title":"ICC from variance components","text":"intra-class agreement usually obtained continuous ratings. example can use data data study Dikmans et al. (2017). data based photographs breasts 50 women breast reconstruction. photographs independently scored 5 surgeons, patients, three mammography nurses. rated quality reconstruction 5 point ordinal scale verbal anchors left side ‘dissatisfied’ left end right end ‘satisfied’ right end. specifically rated volume, shape, symmetry, scars nipple. icc examples can use sum scores volume, shape, symmetry, scars nipple overall rating rater. example data shows missings. icc function can deal missings, mixed model used estimate variances compute icc . mixed model, data needs restructured long format. can use pivot_longer() function tidyr package :","code":"breast_scores <-  Agree::breast %>%   dplyr::select(Patient_score, PCH1_score, PCH2_score, PCH3_score, PCH4_score,                  PCH5_score, Mam1_score, Mam2_score, Mam3_score)  head(breast_scores) >   Patient_score PCH1_score PCH2_score PCH3_score PCH4_score PCH5_score > 1          10.0          9          9          8        7.0          8 > 2            NA          7         NA         NA        8.0          7 > 3           5.5          8          7          7        7.0          8 > 4           7.0         NA          5          4        4.0          8 > 5           1.0          1          2          2        3.0          1 > 6           8.0          8          7         NA        7.5          8 >   Mam1_score Mam2_score Mam3_score > 1          8          8          8 > 2          9          7         NA > 3          8         NA          7 > 4         NA          5         NA > 5          3          3          4 > 6          9          7          7 breast_long <- breast_scores %>%  mutate(id = 1:nrow(breast_scores)) %>% #add id column   pivot_longer(cols = -id, names_to = \"rater\", values_to = \"score\")  breast_long >  [38;5;246m# A tibble: 450 x 3 [39m >       id rater         score >     [3m [38;5;246m<int> [39m [23m  [3m [38;5;246m<chr> [39m [23m          [3m [38;5;246m<dbl> [39m [23m >  [38;5;250m 1 [39m     1 Patient_score    10 >  [38;5;250m 2 [39m     1 PCH1_score        9 >  [38;5;250m 3 [39m     1 PCH2_score        9 >  [38;5;250m 4 [39m     1 PCH3_score        8 >  [38;5;250m 5 [39m     1 PCH4_score        7 >  [38;5;250m 6 [39m     1 PCH5_score        8 >  [38;5;250m 7 [39m     1 Mam1_score        8 >  [38;5;250m 8 [39m     1 Mam2_score        8 >  [38;5;250m 9 [39m     1 Mam3_score        8 >  [38;5;250m10 [39m     2 Patient_score     [31mNA [39m >  [38;5;246m# ... with 440 more rows [39m >  [38;5;246m# i Use `print(n = ...)` to see more rows [39m"},{"path":"/articles/icc_varcomp.html","id":"variance-components","dir":"Articles","previous_headings":"","what":"Variance components","title":"ICC from variance components","text":"variances used compute icc obtained linear mixed model. model estimated lmer() function lme4 package. breast example two levels: patients level 1 raters/observers level 2. two-level multilevel model defined \\(Y_{ijr} = \\beta_0 + b_{0j} + b_{0r} + \\epsilon_{ijr}\\), \\(b_{0j}\\) random intercept subject level \\(b_{0r}\\) random intercept rater/observer level. \\(\\epsilon_{ijr}\\) residual error. r-code model lme4 : lmer(score ~ (1|id) + (1|observer), data, REML = T) De exact specification multilevel model, depends design study type ICC one wants compute.","code":""},{"path":"/articles/icc_varcomp.html","id":"types-of-icc","dir":"Articles","previous_headings":"","what":"Types of ICC","title":"ICC from variance components","text":"three types icc incorporated icc function. ICC oneway, ICC agreement ICC consistency.","code":""},{"path":"/articles/icc_varcomp.html","id":"icc-oneway","dir":"Articles","previous_headings":"Types of ICC","what":"ICC oneway","title":"ICC from variance components","text":"ICC type oneway variance subjects (\\(\\sigma^2_j\\)) divided sum subject variance (\\(\\sigma^2_j\\)) residual variance (\\(\\sigma^2_{\\epsilon}\\)). \\(ICC_{oneway}\\) computed follows: \\(ICC_{oneway} = \\frac{\\sigma^2_j}{\\sigma^2_j + \\sigma^2_{\\epsilon}}\\) ICC oneway assumes subject rated different set raters, randomly selected larger population judges (Shrout Fleis (1979)). icc_oneway() uses varcomp() function compute variance components. variances estimated lmer model random slope subjects. \\(Y_{ij} = \\beta_0 + b_{0j} + \\epsilon_{ij}\\) standard error measurement (\\(sem\\)) square root error variance (.e. \\(sem = \\sigma^2_{\\epsilon}\\)). confidence intervals computed exact F method. \\(F = \\frac{k \\sigma^2_{j} + \\sigma^2_{\\epsilon}}{\\sigma^2_{\\epsilon}}\\), \\(df1 = n - 1\\) \\(df2 = n (k - 1)\\) (Shrout Fleis (1979)). oneway ICC, level 1, patient level, random. rater variance used. r-code extract variance component varcomp function : variance components, can used compute ICC oneway: also incorporated function computed ICC oneway directly data wide format, using steps. icc_oneway function.","code":"varcomp(score~(1|id), data = breast_long) >               grp     vcov > id             id 2.051072 > Residual Residual 1.047193 vc <- varcomp(score~(1|id), data = breast_long) vc[\"id\", \"vcov\"]/sum(vc[,\"vcov\"]) > [1] 0.6620067 icc_oneway(breast_scores) >         icc     L_icc     U_icc      sem varj_oneway varerr_oneway > 1 0.6620067 0.5638296 0.7598147 1.023324    2.051072      1.047193"},{"path":"/articles/icc_varcomp.html","id":"icc-agreement","dir":"Articles","previous_headings":"Types of ICC","what":"ICC agreement","title":"ICC from variance components","text":"icc type agreement variance subjects (\\(\\sigma^2_j\\)) divided sum subject variance (\\(\\sigma^2_j\\)), rater variance (\\(\\sigma^2_k\\)) residual variance (\\(\\sigma^2_\\epsilon\\)). \\(ICC_{agreement}\\) computed follows: \\(ICC_{agreement} = \\frac{\\sigma^2_j}{\\sigma^2_j + \\sigma^2_k + \\sigma^2_{\\epsilon}}\\) ICC agreement generalizes raters within population (Shrout Fleis (1979)). subjects rated set raters, rater variance taken account calculation ICC. variance components computed icc_model() function. lmer model random slope subjects raters. \\(sem\\) square root sum rater variance error variance (.e. \\(sem = \\sqrt{\\sigma^2_r + \\sigma^2_\\epsilon}\\)). confidence intervals approximated account three independent variance components, defined Satterthwaite (1946) & Shrout Fleis (1979). ICC agreement, level 1 level 2 random. r-code extract variance component varcomp function : variance components, can used compute ICC agreement: also incorporated function computed ICC agreement directly data wide format, using steps. icc_agreement function.","code":"varcomp(score ~ (1|id) + (1|rater), data = breast_long) >               grp      vcov > id             id 2.0069835 > rater       rater 0.1167749 > Residual Residual 0.9424505 vc <- varcomp(score~ (1|id) + (1|rater), data = breast_long) vc[\"id\", \"vcov\"]/sum(vc[,\"vcov\"]) > [1] 0.6545488 icc_agreement(breast_scores) >         icc     L_icc   U_icc      sem varj_agr  varr_agr varerr_agr > 1 0.6545488 0.5554292 0.75384 1.029187 2.006984 0.1167749  0.9424505"},{"path":"/articles/icc_varcomp.html","id":"icc-consistency","dir":"Articles","previous_headings":"Types of ICC","what":"ICC consistency","title":"ICC from variance components","text":"ICC type consistency variance subjects (\\(\\sigma^2_j\\)) divided sum subject variance (\\(\\sigma^2_j\\)) residual variance (\\(\\sigma^2_\\epsilon\\)). rater variance used calculate ICC can therefore also considered fixed effect. \\(ICC_{consistency}\\) computed follows: \\(ICC_{consistency} = \\frac{\\sigma^2_j}{\\sigma^2_j + \\sigma^2_{\\epsilon}}\\) ICC consistency generalizes set raters data (Shrout Fleis (1979)). varcomp() function used compute variance components. variances computed lmer model random slope subjects fixed effect raters. sem square root error variance. confidence computed exact F method. \\(F = \\frac{(k \\sigma^2_j + \\sigma^2_\\epsilon)}{\\sigma^2_\\epsilon}\\), \\(df1 = n - 1\\) \\(df2 = (n - 1) (k - 1)\\) (Shrout Fleis (1979)). ICC consistency, level 1 random effect level 2 fixed. r-code extract variance component varcomp function : variance components, can used compute ICC consistency: also incorporated function computed ICC consistency directly data wide format, using steps. icc_consistency function.","code":"varcomp(score ~ (1|id) + rater, data = breast_long) >               grp      vcov > id             id 1.9956492 > Residual Residual 0.9428479 vc <- varcomp(score~ (1|id) + rater, data = breast_long) vc[\"id\", \"vcov\"]/sum(vc[,\"vcov\"]) > [1] 0.6791394 icc_consistency(breast_scores) >         icc     L_icc     U_icc       sem varj_cons varerr_cons > 1 0.6791394 0.5831551 0.7734836 0.9710035  1.995649   0.9428479"},{"path":"/articles/icc_varcomp.html","id":"comparing-icc-types","dir":"Articles","previous_headings":"Types of ICC","what":"Comparing ICC types","title":"ICC from variance components","text":"one general icc function computes three ICC types data set. differences computations ICC types can quickly seen variance components returned icc function. can obtain variances using var = TRUE icc() function, var_level2 shows variance raters. ICC agreement variance component estimated. estimate ICC surgeons , can see variance rater level decreased. effect directly shown ICC. icc can also use data wide format use cols option define rater columns want use. estimate ICC mammography nurses , see variance rater level increased. effect directly shown ICC.","code":"# ICC for all methods icc(breast_scores, var = TRUE) >                   icc     lower     upper       sem var_level1 var_level2 > oneway      0.6620067 0.5638296 0.7598147 1.0233245   2.051072         NA > agreement   0.6545488 0.5554292 0.7538400 1.0291868   2.006984  0.1167749 > consistency 0.6791394 0.5831551 0.7734836 0.9710035   1.995649         NA >             var_Residual > oneway         1.0471930 > agreement      0.9424505 > consistency    0.9428479 # ICC for all methods icc(breast_scores,      cols = c(\"PCH1_score\", \"PCH2_score\", \"PCH3_score\", \"PCH4_score\", \"PCH5_score\"),      var = TRUE) >                   icc     lower     upper       sem var_level1 var_level2 > oneway      0.7615871 0.6710817 0.8403886 0.8591071   2.357677         NA > agreement   0.7593693 0.6682981 0.8387870 0.8611481   2.340225 0.05026114 > consistency 0.7711953 0.6829366 0.8473933 0.8317713   2.331886         NA >             var_Residual > oneway         0.7380650 > agreement      0.6913149 > consistency    0.6918435 # ICC for all methods icc(breast_scores,      cols = c(\"Mam1_score\", \"Mam2_score\", \"Mam3_score\"),      var = TRUE) >                   icc     lower     upper       sem var_level1 var_level2 > oneway      0.6001478 0.4493754 0.7309390 1.1515241   1.990237         NA > agreement   0.5698257 0.4137129 0.7079019 1.1919337   1.881923  0.4443499 > consistency 0.6558989 0.5162467 0.7724701 0.9899547   1.868020         NA >             var_Residual > oneway         1.3260076 > agreement      0.9763561 > consistency    0.9800104"},{"path":[]},{"path":[]},{"path":"/articles/polytomous.html","id":"ordinal-data-example","dir":"Articles","previous_headings":"","what":"Ordinal data example","title":"Agreement for polytomous outcomes","text":"ordinal data example use data study Dikmans et al. (2017). data based photographs breasts 50 women breast reconstruction. photographs independently scored 5 surgeons, patients, three mothers. rated quality reconstruction 5 point ordinal scale verbal anchors left side ‘dissatisfied’ left end right end ‘satisfied’ right end. specifically rated volume, shape, symmetry, scars nipple. paper use data 4 surgeons one surgeon missing values look rates symmetry. Data set 1 used example ordinal categories.","code":"data(breast)  variable <- \"symmetry\" raters <- c(\"PCH1\", \"PCH2\", \"PCH3\", \"PCH4\") ratersvars <- paste(raters, variable, sep=\"_\") data1 <- data.frame(breast[ratersvars])  data1 %>% head() ##       PCH1_symmetry  PCH2_symmetry PCH3_symmetry PCH4_symmetry ## 1         satisfied very satisfied     satisfied     satisfied ## 2           neutral        neutral  dissatisfied       neutral ## 3         satisfied        neutral       neutral       neutral ## 4      dissatisfied        neutral  dissatisfied  dissatisfied ## 5 very dissatisfied      satisfied  dissatisfied     satisfied ## 6         satisfied        neutral     satisfied     satisfied"},{"path":"/articles/polytomous.html","id":"agreement-table","dir":"Articles","previous_headings":"Ordinal data example","what":"Agreement table","title":"Agreement for polytomous outcomes","text":"First agreement table summed rater combinations one agreement table. diagonal cells averaged obtain symmetry agreement tables.","code":"sumtable(data1,offdiag = FALSE) %>% kable() sumtable(data1,offdiag = TRUE) %>% kable()"},{"path":"/articles/polytomous.html","id":"agreement","dir":"Articles","previous_headings":"Ordinal data example","what":"Agreement","title":"Agreement for polytomous outcomes","text":"agreement table can calculate agreement. can calculate confidence interval around agreement.","code":"agreement(data1) ## overall agreement  ##         0.4333333 agreement(data1, confint = TRUE) ## overall agreement             lower             upper  ##         0.4333333         0.3286321         0.5434725"},{"path":"/articles/polytomous.html","id":"specific-agreement","dir":"Articles","previous_headings":"Ordinal data example","what":"Specific agreement","title":"Agreement for polytomous outcomes","text":"specific agreement polytomous data, can defined two ways: agreement one category versus category (e.g. satisfied versus categories) agreement one category versus (e.g. satistfied versus satisfied). Confidence intervals specific agreements bootstrapped.","code":"agreement(data1, specific=\"satisfied\", confint = TRUE) ##                                       p     lower     upper ## overall agreement             0.4333333 0.3286321 0.5434725 ## specific agreement: satisfied 0.3163842 0.2221154 0.3935024 agreement(data1, specific=c(\"satisfied\", \"very satisfied\"), confint = TRUE) ##                                                         p     lower     upper ## overall agreement                               0.4333333 0.3286321 0.5434725 ## specific agreement: satisfied vs very satisfied 0.5185185 0.3673031 0.6555140 agreement(data1, specific= c(\"satisfied\",\"neutral\"), confint = TRUE) ##                                                  p     lower     upper ## overall agreement                        0.4333333 0.3286321 0.5434725 ## specific agreement: satisfied vs neutral 0.5045045 0.3801612 0.6250272"},{"path":"/articles/polytomous.html","id":"conditional-probability","dir":"Articles","previous_headings":"Ordinal data example","what":"Conditional probability","title":"Agreement for polytomous outcomes","text":"can calulate probability outcome conditional specific outcome.","code":"conditional.agreement(data1) %>% kable()"},{"path":"/articles/polytomous.html","id":"weighted-agreement","dir":"Articles","previous_headings":"Ordinal data example","what":"Weighted agreement","title":"Agreement for polytomous outcomes","text":"ordinal data might also useful look agreement may one category . agreement plus minus one category, categories weighted (default weight=1).","code":"weighted.agreement(data1) ## [1] 0.93 weighted.agreement(data1, weight=0.5) ## [1] 0.6816667"},{"path":"/articles/polytomous.html","id":"nominal-data-example","dir":"Articles","previous_headings":"","what":"nominal data example","title":"Agreement for polytomous outcomes","text":"nominal data example use data set used paper Fleis (1971). data patients diagnosed 5 categories: Depression, Personality Disorder, Schizophrenia, Neurosis, 6 raters.","code":"data(diagnoses)  data2 <- data.frame(lapply(diagnoses,as.factor), stringsAsFactors = TRUE)   levels(data2$rater1) <- c(\"Depression\", \"Pers disord.\", \"Schizophrenia\", \"Neurosis\", \"Other\")  levels(data2$rater2) <- c(\"Depression\", \"Pers disord.\", \"Schizophrenia\", \"Neurosis\", \"Other\")  levels(data2$rater3) <- c(\"Depression\", \"Pers disord.\", \"Schizophrenia\", \"Neurosis\", \"Other\")  levels(data2$rater4) <- c(\"Depression\", \"Pers disord.\", \"Schizophrenia\", \"Neurosis\", \"Other\")  levels(data2$rater5) <- c(\"Depression\", \"Pers disord.\", \"Schizophrenia\", \"Neurosis\", \"Other\")"},{"path":"/articles/polytomous.html","id":"agreement-table-1","dir":"Articles","previous_headings":"nominal data example","what":"Agreement table","title":"Agreement for polytomous outcomes","text":"First agreement table summed rater combinations one agreement table. diagonal cells averaged obtain symmetry agreement tables.","code":"sumtable(data2,offdiag = FALSE) %>% kable() sumtable(data2,offdiag = TRUE) %>% kable()"},{"path":"/articles/polytomous.html","id":"agreement-1","dir":"Articles","previous_headings":"nominal data example","what":"Agreement","title":"Agreement for polytomous outcomes","text":"agreement table can calculate agreement. can calculate confidence interval around agreement.","code":"agreement(data2, confint = TRUE) ## overall agreement             lower             upper  ##         0.3955556         0.2805873         0.5200202"},{"path":"/articles/polytomous.html","id":"specific-agreement-1","dir":"Articles","previous_headings":"nominal data example","what":"Specific agreement","title":"Agreement for polytomous outcomes","text":"specific agreement polytomous data, can defined two ways: agreement one category versus category (e.g. Depression versus categories) agreement one category versus (e.g. Depression versus Schizophrenia). confidence intervals specific agreement bootstrapped.","code":"agreement(data2, specific=\"Depression\", confint = TRUE) ##                                        p     lower     upper ## overall agreement              0.3955556 0.2805873 0.5200202 ## specific agreement: Depression 0.3538462 0.1051316 0.5285924 agreement(data2, specific=\"Pers disord.\", confint = TRUE) ##                                          p     lower     upper ## overall agreement                0.3955556 0.2805873 0.5200202 ## specific agreement: Pers disord. 0.3680000 0.1750000 0.5517241 agreement(data2, specific=\"Schizophrenia\", confint = TRUE) ##                                           p     lower     upper ## overall agreement                 0.3955556 0.2805873 0.5200202 ## specific agreement: Schizophrenia 0.5333333 0.3777083 0.6625229 agreement(data2, specific=\"Neurosis\", confint = TRUE) ##                                      p     lower     upper ## overall agreement            0.3955556 0.2805873 0.5200202 ## specific agreement: Neurosis 0.4930233 0.3874899 0.5793174 agreement(data2, specific=\"Other\", confint = TRUE) ##                                   p     lower     upper ## overall agreement         0.3955556 0.2805873 0.5200202 ## specific agreement: Other 0.5931034 0.3111111 0.7285714"},{"path":"/articles/polytomous.html","id":"conditional-agreement","dir":"Articles","previous_headings":"nominal data example","what":"Conditional agreement","title":"Agreement for polytomous outcomes","text":"","code":"conditional.agreement(data2) %>% kable()"},{"path":[]},{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Iris Eekhout. Author, maintainer.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Eekhout (2022). Agree: Agreement reliability multiple raters. R package version 0.1.9.","code":"@Manual{,   title = {Agree: Agreement and reliability between multiple raters},   author = {Iris Eekhout},   year = {2022},   note = {R package version 0.1.9}, }"},{"path":"/index.html","id":"agree","dir":"","previous_headings":"","what":"Agreement and reliability between multiple raters","title":"Agreement and reliability between multiple raters","text":"Agree package developed calculate agreement reliability scores multiple raters repeated measurments. (proportion) agreement multiple raters can calculated dichotomous scores well polytomous scores. confidence interval around agreement can calculated, adjusted multiple raters. Additionally, Intra Class Correlation (ICC) Standard Error Measurement (SEM) can calculated continuous scores. can obtained estimated variance components extracted multilevel model.","code":""},{"path":"/index.html","id":"package-installation","dir":"","previous_headings":"","what":"Package installation","title":"Agreement and reliability between multiple raters","text":"package can installed directly GitHub remotes::install_github(repo = 'iriseekhout/Agree')","code":""},{"path":"/index.html","id":"agreement-for-dichotomous-outcomes","dir":"","previous_headings":"","what":"Agreement for dichotomous outcomes","title":"Agreement and reliability between multiple raters","text":"use Agree package data example used paper specific agreement dichotomous outcomes situation two raters. method fully explained described de Vet, Dikmans & Eekhout (2017).","code":""},{"path":"/index.html","id":"dichotomous-example-data","dir":"","previous_headings":"Agreement for dichotomous outcomes","what":"Dichotomous example data","title":"Agreement and reliability between multiple raters","text":"example used data study Dikmans et al. (2017). data based photographs breasts 50 women breast reconstruction. photographs independently scored 5 surgeons, patient, three mothers. rated quality reconstruction 5 point ordinal scale verbal anchors left side ‘dissatisfied’ left end right end ‘satisfied’ right end. specifically rated volume, shape, symmetry, scars nipple. paper use data 4 surgeons one surgeon missing values look rates symmetry. satisfaction scores dichotomised satisfied (scores 4 5) satisfied (scores 1,2, 3).","code":"data(breast) variable <- \"symmetry\" raters <- c(\"PCH1\", \"PCH2\", \"PCH3\", \"PCH4\") ratersvars <- paste(raters, variable, sep=\"_\") data1 <- data.frame(breast[ratersvars])  for (r in 1:length(ratersvars)){     data1[ratersvars[r]] <- ifelse(data1[ratersvars[r]]==\"very satisfied\"|data1[ratersvars[r]]==\"satisfied\",\"satisfied\",\"not satisfied\")  } data1 <- data.frame(apply(data1[ratersvars], 2, as.factor), stringsAsFactors = TRUE)"},{"path":"/index.html","id":"agreement-table","dir":"","previous_headings":"Agreement for dichotomous outcomes","what":"Agreement table","title":"Agreement and reliability between multiple raters","text":"First agreement tables summed rater combinations one agreement table. diagonal cells averaged obtain symmetry agreement tables. Note data1 contains column per rater variable interest.","code":"sumtable(data1,offdiag = FALSE)  sumtable(data1,offdiag = TRUE)"},{"path":"/index.html","id":"agreement","dir":"","previous_headings":"Agreement for dichotomous outcomes","what":"Agreement","title":"Agreement and reliability between multiple raters","text":"agreement table can calculate agreement. can calculate confidence interval around agreement.","code":"agreement(data1, confint = TRUE)"},{"path":"/index.html","id":"specific-agreement","dir":"","previous_headings":"Agreement for dichotomous outcomes","what":"Specific agreement","title":"Agreement and reliability between multiple raters","text":"specific agreement dichotomous data can evaluated satisfied scores satisfied scores.","code":"agreement(data1, specific=\"satisfied\", confint = TRUE) agreement(data1, specific=\"not satisfied\", confint = TRUE)"},{"path":"/index.html","id":"polytomous-outcomes","dir":"","previous_headings":"","what":"Polytomous outcomes","title":"Agreement and reliability between multiple raters","text":"use Agree package two data examples used paper specific agreement polytomous outcomes situation two raters (de Vet, Mullender, Eekhout, 2018). first data example example ordinal ratings second example nominal rating.","code":""},{"path":"/index.html","id":"ordinal-example-data","dir":"","previous_headings":"Polytomous outcomes","what":"Ordinal example data","title":"Agreement and reliability between multiple raters","text":"ordinal data example use data study Dikmans et al. (2017). data based photographs breasts 50 women breast reconstruction. photographs independently scored 5 surgeons, patients, three mothers. rated quality reconstruction 5 point ordinal scale verbal anchors left side ‘dissatisfied’ left end right end ‘satisfied’ right end. specifically rated volume, shape, symmetry, scars nipple. paper use data 4 surgeons one surgeon missing values look rates symmetry. Data set 1 used example ordinal categories.","code":"data(breast)  variable <- \"symmetry\" raters <- c(\"PCH1\", \"PCH2\", \"PCH3\", \"PCH4\") ratersvars <- paste(raters, variable, sep=\"_\") data1 <- data.frame(breast[ratersvars])"},{"path":"/index.html","id":"agreement-table-1","dir":"","previous_headings":"Polytomous outcomes","what":"Agreement table","title":"Agreement and reliability between multiple raters","text":"First agreement table summed rater combinations one agreement table. diagonal cells averaged obtain symmetry agreement tables.","code":"sumtable(data1,offdiag = FALSE) sumtable(data1,offdiag = TRUE)"},{"path":"/index.html","id":"agreement-1","dir":"","previous_headings":"Polytomous outcomes","what":"Agreement","title":"Agreement and reliability between multiple raters","text":"agreement table can calculate agreement. can calculate confidence interval around agreement.","code":"agreement(data1, confint = TRUE)"},{"path":"/index.html","id":"specific-agreement-1","dir":"","previous_headings":"Polytomous outcomes","what":"Specific agreement","title":"Agreement and reliability between multiple raters","text":"specific agreement polytomous data, can defined two ways: agreement one category versus category (e.g. satisfied versus categories) agreement one category versus (e.g. satistfied versus satisfied). Confidence intervals specific agreements bootstrapped.","code":"agreement(data1, specific=\"satisfied\", confint = TRUE) agreement(data1, specific=c(\"satisfied\", \"very satisfied\"), confint = TRUE) agreement(data1, specific= c(\"satisfied\",\"neutral\"), confint = TRUE)"},{"path":"/index.html","id":"conditional-probability","dir":"","previous_headings":"Polytomous outcomes","what":"Conditional probability","title":"Agreement and reliability between multiple raters","text":"can calulate probability outcome conditional specific outcome.","code":"conditional.agreement(data1)"},{"path":"/index.html","id":"weighted-agreement","dir":"","previous_headings":"Polytomous outcomes","what":"Weighted agreement","title":"Agreement and reliability between multiple raters","text":"ordinal data might also useful look agreement may one category . agreement plus minus one category, categories weighted (default weight=1).","code":"weighted.agreement(data1) weighted.agreement(data1, weight=0.5)"},{"path":"/index.html","id":"nominal-example-data","dir":"","previous_headings":"Polytomous outcomes","what":"Nominal example data","title":"Agreement and reliability between multiple raters","text":"nominal data example use data set used paper Fleis (1971). data patients diagnosed 5 categories: Depression, Personality Disorder, Schizophrenia, Neurosis, 6 raters.","code":"data(diagnoses)  data2 <- data.frame(lapply(diagnoses,as.factor), stringsAsFactors = TRUE)   levels(data2$rater1) <- c(\"Depression\", \"Pers disord.\", \"Schizophrenia\", \"Neurosis\", \"Other\")  levels(data2$rater2) <- c(\"Depression\", \"Pers disord.\", \"Schizophrenia\", \"Neurosis\", \"Other\")  levels(data2$rater3) <- c(\"Depression\", \"Pers disord.\", \"Schizophrenia\", \"Neurosis\", \"Other\")  levels(data2$rater4) <- c(\"Depression\", \"Pers disord.\", \"Schizophrenia\", \"Neurosis\", \"Other\")  levels(data2$rater5) <- c(\"Depression\", \"Pers disord.\", \"Schizophrenia\", \"Neurosis\", \"Other\")"},{"path":"/index.html","id":"agreement-table-2","dir":"","previous_headings":"Polytomous outcomes","what":"Agreement table","title":"Agreement and reliability between multiple raters","text":"First agreement table summed rater combinations one agreement table. diagonal cells averaged obtain symmetry agreement tables.","code":"sumtable(data2,offdiag = FALSE)  sumtable(data2,offdiag = TRUE)"},{"path":"/index.html","id":"agreement-2","dir":"","previous_headings":"Polytomous outcomes","what":"Agreement","title":"Agreement and reliability between multiple raters","text":"agreement table can calculate agreement. can calculate confidence interval around agreement.","code":"agreement(data2, confint = TRUE)"},{"path":"/index.html","id":"specific-agreement-2","dir":"","previous_headings":"Polytomous outcomes","what":"Specific agreement","title":"Agreement and reliability between multiple raters","text":"specific agreement polytomous data, can defined two ways: agreement one category versus category (e.g. Depression versus categories) agreement one category versus (e.g. Depression versus Schizophrenia). confidence intervals specific agreement bootstrapped.","code":"agreement(data2, specific=\"Depression\", confint = TRUE) agreement(data2, specific=\"Pers disord.\", confint = TRUE) agreement(data2, specific=\"Schizophrenia\", confint = TRUE) agreement(data2, specific=\"Neurosis\", confint = TRUE) agreement(data2, specific=\"Other\", confint = TRUE)"},{"path":"/index.html","id":"conditional-agreement","dir":"","previous_headings":"Polytomous outcomes","what":"Conditional agreement","title":"Agreement and reliability between multiple raters","text":"","code":"conditional.agreement(data2) %>% kable()"},{"path":"/index.html","id":"estimating-iccs-and-sems-with-multilevel-models","dir":"","previous_headings":"","what":"Estimating ICCs and SEMs with multilevel models","title":"Agreement and reliability between multiple raters","text":"computational background use icc() function Agree package. developed icc() functions package connection simulation study sample size requirements studies reliability measurement error (Mokkink et al, tbp) methodological paper design conduct study reliability measurement error (Mokkink et al tbp).","code":""},{"path":"/index.html","id":"continuous-example-data","dir":"","previous_headings":"Estimating ICCs and SEMs with multilevel models","what":"Continuous example data","title":"Agreement and reliability between multiple raters","text":"intra-class agreement usually obtained continuous ratings. example can use data data study Dikmans et al. (2017). data based photographs breasts 50 women breast reconstruction. photographs independently scored 5 surgeons, patients, three mammography nurses. rated quality reconstruction 5 point ordinal scale verbal anchors left side ‘dissatisfied’ left end right end ‘satisfied’ right end. specifically rated volume, shape, symmetry, scars nipple. icc examples can use sum scores volume, shape, symmetry, scars nipple overall rating rater. example data shows missings. icc function can deal missings, mixed model used estimate variances compute icc . mixed model, data needs restructured long format. can use pivot_longer() function tidyr package :","code":"breast_scores <-  Agree::breast %>%   dplyr::select(Patient_score, PCH1_score, PCH2_score, PCH3_score, PCH4_score,                  PCH5_score, Mam1_score, Mam2_score, Mam3_score) breast_long <- breast_scores %>%  mutate(id = 1:nrow(breast_scores)) %>% #add id column   pivot_longer(cols = -id, names_to = \"rater\", values_to = \"score\")  breast_long"},{"path":"/index.html","id":"variance-components","dir":"","previous_headings":"Estimating ICCs and SEMs with multilevel models","what":"Variance components","title":"Agreement and reliability between multiple raters","text":"variances used compute icc obtained linear mixed model. model estimated lmer() function lme4 package. breast example two levels: patients level 1 raters/observers level 2. two-level multilevel model defined Yijr = β0 + b0j + b0r + εijr, β0 random intercept subject level β0r random intercept rater/observer level. εijr residual error. r-code model lme4 : lmer(score ~ (1|id) + (1|observer), data, REML = T) De exact specification multilevel model, depends design study type ICC one wants compute.","code":""},{"path":"/index.html","id":"types-of-icc","dir":"","previous_headings":"Estimating ICCs and SEMs with multilevel models","what":"Types of ICC","title":"Agreement and reliability between multiple raters","text":"three types icc incorporated icc function. ICC oneway, ICC agreement ICC consistency.","code":""},{"path":"/index.html","id":"icc-oneway","dir":"","previous_headings":"Estimating ICCs and SEMs with multilevel models > Types of ICC","what":"ICC oneway","title":"Agreement and reliability between multiple raters","text":"ICC type oneway variance subjects (σ2j) divided sum subject variance (σ2j) residual variance (σ2ε). ICConeway computed follows: ICConeway = σ2j / (σ2j + σ2ε) ICC oneway assumes subject rated different set raters, randomly selected larger population judges (Shrout & Fleis, 1979). icc_oneway() uses varcomp() function compute variance components. variances estimated lmer model random slope subjects. Yij = β0 + b0j + εij standard error measurement (SEM) square root error variance (.e. SEM = √σ2ε). confidence intervals computed exact F method. F = (k σ2j + σ2ε) / σ2ε, df1 = n - 1 df2 = n (k - 1) (Shrout & Fleis, 1979). oneway ICC, level 1, patient level, random. rater variance used. r-code extract variance component varcomp function : variance components, can used compute ICC oneway: also incorporated function computed ICC oneway directly data wide format, using steps. icc_oneway function.","code":"varcomp(score~(1|id), data = breast_long) vc <- varcomp(score~(1|id), data = breast_long) vc[\"id\", \"vcov\"]/sum(vc[,\"vcov\"]) icc_oneway(breast_scores)"},{"path":"/index.html","id":"icc-agreement","dir":"","previous_headings":"Estimating ICCs and SEMs with multilevel models > Types of ICC","what":"ICC agreement","title":"Agreement and reliability between multiple raters","text":"icc type agreement variance subjects (σ2j) divided sum subject variance (σ2j), rater variance (σ2k) residual variance (σ2ε). ICCagreement computed follows: ICCagreement = σ2j / (σ2j + σ2k + σ2ε) ICC agreement generalizes raters within population (Shrout & Fleis, 1979). subjects rated set raters, rater variance taken account calculation ICC. variance components computed icc_model() function. lmer model random slope subjects raters. SEM square root sum rater variance error variance (.e. SEM = √σ2r + σ2ε). confidence intervals approximated account three independent variance components, defined Satterthwaite (1946) & Shrout & Fleis (1979). ICC agreement, level 1 level 2 random. r-code extract variance component varcomp function : variance components, can used compute ICC agreement: also incorporated function computed ICC agreement directly data wide format, using steps. icc_agreement function.","code":"varcomp(score ~ (1|id) + (1|rater), data = breast_long) vc <- varcomp(score~ (1|id) + (1|rater), data = breast_long) vc[\"id\", \"vcov\"]/sum(vc[,\"vcov\"]) icc_agreement(breast_scores)"},{"path":"/index.html","id":"icc-consistency","dir":"","previous_headings":"Estimating ICCs and SEMs with multilevel models > Types of ICC","what":"ICC consistency","title":"Agreement and reliability between multiple raters","text":"ICC type consistency variance subjects (σ2j) divided sum subject variance (σ2j) residual variance (σ2ε). rater variance used calculate ICC can therefore also considered fixed effect. ICCconsistency computed follows: ICCconsistency = σ2j  (σ2j + σ2ε) ICC consistency generalizes set raters data (Shrout & Fleis, 1979). varcomp() function used compute variance components. variances computed lmer model random slope subjects fixed effect raters. sem square root error variance. confidence computed exact F method. F = (k σ2j + σ2ε) / σ2ε , df1 = n - 1 df2 = (n - 1) (k - 1) (Shrout & Fleis, 1979). ICC consistency, level 1 random effect level 2 fixed. r-code extract variance component varcomp function : variance components, can used compute ICC consistency: also incorporated function computed ICC consistency directly data wide format, using steps. icc_consistency function.","code":"varcomp(score ~ (1|id) + rater, data = breast_long) vc <- varcomp(score~ (1|id) + rater, data = breast_long) vc[\"id\", \"vcov\"]/sum(vc[,\"vcov\"]) icc_consistency(breast_scores)"},{"path":"/index.html","id":"comparing-icc-types","dir":"","previous_headings":"Estimating ICCs and SEMs with multilevel models","what":"Comparing ICC types","title":"Agreement and reliability between multiple raters","text":"one general icc function computes three ICC types data set. differences computations ICC types can quickly seen variance components returned icc function. can obtain variances using var = TRUE icc() function, var_level2 shows variance raters. ICC agreement variance component estimated. estimate ICC surgeons , can see variance rater level decreased. effect directly shown ICC. icc can also use data wide format use cols option define rater columns want use. estimate ICC mammography nurses , see variance rater level increased. effect directly shown ICC.","code":"# ICC for all methods icc(breast_scores, var = TRUE) # ICC for all methods icc(breast_scores,      cols = c(\"PCH1_score\", \"PCH2_score\", \"PCH3_score\", \"PCH4_score\", \"PCH5_score\"),      var = TRUE) # ICC for all methods icc(breast_scores,      cols = c(\"Mam1_score\", \"Mam2_score\", \"Mam3_score\"),      var = TRUE)"},{"path":"/index.html","id":"three-way-models","dir":"","previous_headings":"Estimating ICCs and SEMs with multilevel models","what":"Three-way models","title":"Agreement and reliability between multiple raters","text":"three-way effects models extension two-way effects models extra random fixed effect. additional effect can defined lmer formula varcomp function.","code":"# variance components for a three-way model for agreement varcomp(score ~ (1|id) + (1|rater) + (1|technician), data)  # variance components for a three-way mixed model for consistency with fixed rater and technician varcomp(score ~ (1|id) + rater + technician, data)  # variance components for a three-way mixed model for consistency with fixed technician varcomp(score ~ (1|id) + (1|rater) + technician, data)"},{"path":[]},{"path":"/reference/Agree-deprecated.html","id":null,"dir":"Reference","previous_headings":"","what":"Deprecated functions in package Agree. — Agree-deprecated","title":"Deprecated functions in package Agree. — Agree-deprecated","text":"functions listed deprecated defunct   near future. possible, alternative functions similar   functionality also mentioned. Help pages deprecated functions   available help(\"<function>-deprecated\").","code":""},{"path":"/reference/Agree-deprecated.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Deprecated functions in package Agree. — Agree-deprecated","text":"","code":"positive.agreement(data, specific = \"positive\", ...)  specific.agreement(data, cat1, cat2 = NULL, ...)  CIagreement(   data,   interval = 0.95,   cat1 = NULL,   cat2 = NULL,   m = NULL,   n = NULL,   b = 1000 )"},{"path":"/reference/Agree-deprecated.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Deprecated functions in package Agree. — Agree-deprecated","text":"following functions deprecated made defunct; use replacement indicated : positive.agreement: agreement specific.agreement: agreement CIagreement: agreement","code":""},{"path":"/reference/Agree-deprecated.html","id":"positive-agreement","dir":"Reference","previous_headings":"","what":"positive.agreement","title":"Deprecated functions in package Agree. — Agree-deprecated","text":"positive.agreement, use agreement.","code":""},{"path":"/reference/Agree-deprecated.html","id":"specific-agreement","dir":"Reference","previous_headings":"","what":"specific.agreement","title":"Deprecated functions in package Agree. — Agree-deprecated","text":"specific.agreement, use agreement.","code":""},{"path":"/reference/Agree-deprecated.html","id":"ciagreement","dir":"Reference","previous_headings":"","what":"CIagreement","title":"Deprecated functions in package Agree. — Agree-deprecated","text":"CIagreement, use agreement.","code":""},{"path":"/reference/agreement.html","id":null,"dir":"Reference","previous_headings":"","what":"Agreement — agreement","title":"Agreement — agreement","text":"default function returns proportion overall agreement two raters. Specific agreements can obtained well. Specific agreement (averages discordant cells correct random rater combinations). 2 categories, equal positive/negative agreement. two categories, one can either look agreement one category versus others, example satisfied versus rest one category versus one specific category, example satisfies versus satisfied.","code":""},{"path":"/reference/agreement.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Agreement — agreement","text":"","code":"agreement(   data,   specific = NULL,   confint = FALSE,   alpha = 0.05,   n = nrow(data),   k = ncol(data),   b = 1000,   ... )"},{"path":"/reference/agreement.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Agreement — agreement","text":"data data frame table equal number columns rows. data frame contains scores rater column. specific character vector indicating category specific agreement calculated. length(specific) == 1, named factor level compared others, length(specific) == 2 specific agreement first category level compared second category level. specific = \"positive\" specific = \"negative\" scores dichotomous, positive negative agreement returned. confint logical vector confidence interval agreements computed. alpha confidence interval level n sample size; default n = nrow(data) k number raters; default k = ncol(data) b number bootstrap iterations bootstrapped CI ... options sumtable data = data.frame","code":""},{"path":"/reference/agreement.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Agreement — agreement","text":"S3 object containing proportion overall agreement.","code":""},{"path":"/reference/agreement.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Agreement — agreement","text":"De confidence intervals obtained adjusted Fleis continuity correction. specific agreements polytomous data, confidence intervals bootstrapped.","code":""},{"path":"/reference/agreement.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Agreement — agreement","text":"","code":"#dichotomous df <- data.frame(r1=factor(c(1,0,1,0,0,1,1,0,0,0,1,1,0,1,1)),                  r2=factor(c(1,1,1,1,0,1,1,0,0,0,1,1,0,1,0)),                  r3=factor(c(1,1,1,0,0,0,1,1,1,0,0,1,0,1,1)),                  r4=factor(c(1,1,1,1,1,1,1,1,1,1,1,1,1,1,1))) table <- sumtable(df=df, ratings=c(\"r1\", \"r2\", \"r3\", \"r4\"), levels=c(\"0\",\"1\")) agreement(table) #> overall agreement  #>         0.6333333  agreement(table, specific = \"1\") #>     overall agreement specific agreement: 1  #>             0.6333333             0.7317073  agreement(table, specific = \"1\", confint = TRUE) #>                               p     lower     upper #> overall agreement     0.6333333 0.2154740 0.8617275 #> specific agreement: 1 0.7317073 0.6199105 0.8259595 agreement(table, specific = \"positive\") #>  overall agreement positive agreement  #>          0.6333333          0.4210526  agreement(df) #> overall agreement  #>         0.6333333  agreement(df, specific = \"1\") #>     overall agreement specific agreement: 1  #>             0.6333333             0.7317073  agreement(df, specific = \"positive\") #>  overall agreement positive agreement  #>          0.6333333          0.4210526  agreement(df, specific = \"negative\") #>  overall agreement negative agreement  #>          0.6333333          0.7317073  #polytomous df <- data.frame(r1=factor(c(1,2,2,0,3,3,1,0,3,0,2,2,0,3,1)),                  r2=factor(c(1,1,1,0,3,3,1,0,1,0,2,2,0,2,1)),                  r3=factor(c(1,1,1,3,3,2,1,0,1,0,2,2,0,3,1)),                  r4=factor(c(1,2,1,0,3,3,1,0,3,0,2,2,0,2,1))) table <- sumtable(df=df, ratings=c(\"r1\", \"r2\", \"r3\", \"r4\"), levels=c(\"0\",\"1\", \"2\", \"3\")) agreement(table, specific = c(\"3\", \"1\")) #>          overall agreement specific agreement: 3 vs 1  #>                  0.7666667                  0.8461538  agreement(table, specific = c(\"3\", \"1\", \"2\")) #> Warning: The specific agreement cannot be obtained for more than two categories; only the first argument is used and compared to all other category levels available. To avoid this warning use: specific = 3 #>     overall agreement specific agreement: 3  #>             0.7666667             0.6111111  agreement(table, specific = c(3)) #>     overall agreement specific agreement: 3  #>             0.7666667             0.6666667  agreement(table, specific = c(\"3\", \"1\"), confint = TRUE) #> Warning: input should be a data.frame to obtain confidence intervals for specific agreement with more than 2 factor levels; confinterval are not returned #>          overall agreement specific agreement: 3 vs 1  #>                  0.7666667                  0.8461538  agreement(df, specific = c(\"3\", \"1\"), confint = TRUE) #>                                    p     lower     upper #> overall agreement          0.7666667 0.6232767 0.8747149 #> specific agreement: 3 vs 1 0.8461538 0.4000000 1.0000000"},{"path":"/reference/bootCI.html","id":null,"dir":"Reference","previous_headings":"","what":"bootCI — bootCI","title":"bootCI — bootCI","text":"bootCI","code":""},{"path":"/reference/bootCI.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"bootCI — bootCI","text":"","code":"bootCI(data, b = 1000, alpha = 0.05, fun, ...)"},{"path":"/reference/bootCI.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"bootCI — bootCI","text":"data data.frame bootstraps need performed obtain confidence intervals. b number bootstrap replications alpha level Confidence interval, default alpha = 0.05 fun function estimate parameter CI determined. ... additional parameters function","code":""},{"path":"/reference/bootCI.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"bootCI — bootCI","text":"named vector confidence interval levels","code":""},{"path":"/reference/bootCI.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"bootCI — bootCI","text":"","code":"if (FALSE) { agreement(diagnoses) bootCI(data = diagnoses, fun = agreement) agreement(diagnoses, specific = \"4. Neurosis\") bootCI(data = diagnoses, fun = agreement, specific = \"4. Neurosis\") ## bootsctrap CI for SEM agreement icc(data = breast[,c(\"PCH1_score\", \"PCH2_score\", \"PCH3_score\")], method = \"agreement\", confint = FALSE)[\"sem\"] sem_a <- function(x){icc(data = x, method = \"agreement\", confint = FALSE)[\"sem\"]} sem_a <- function(x){unlist(icc_agreement(x)[\"sem\"])} bootCI(data = breast[,c(\"PCH1_score\", \"PCH2_score\", \"PCH3_score\")], fun = sem_a) }"},{"path":"/reference/breast.html","id":null,"dir":"Reference","previous_headings":"","what":"breast — breast","title":"breast — breast","text":"data example used data study Dikmans et al (2017). data based photographs breasts 50 women breast reconstruction. photographs  independently scored 5 surgeons, patient, three mothers. rated quality reconstruction 5 point ordinal scale verbal anchors left side ‘dissatisfied’ left end right end ‘satisfied’ right end. specifically rated volume, shape, symmetry, scars nipple.","code":""},{"path":"/reference/breast.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"breast — breast","text":"","code":"breast"},{"path":"/reference/breast.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"breast — breast","text":"data frame 50 rows 55 variables: Qnumber id number Patient_volume Rate volume breast 5pt likert patient Patient_shape Rate shape breast 5pt likert patient Patient_symmetry Rate symmetry breast 5pt likert patient Patient_scars Rate scars breast 5pt likert patient Patient_nipple Rate nipple breast 5pt likert patient Patient_score Mean score breast satisfaction patient PCH1_volume Rate volume breast 5pt likert surgeon1 PCH1_shape Rate shape breast 5pt likert surgeon1 PCH1_symmetry Rate symmetry breast 5pt likert surgeon1 PCH1_scars Rate scars breast 5pt likert surgeon1 PCH1_nipple Rate nipple breast 5pt likert surgeon1 PCH1_score Mean score breast satisfaction surgeon1 PCH2_volume Rate volume breast 5pt likert surgeon2 PCH2_shape Rate shape breast 5pt likert surgeon2 PCH2_symmetry Rate symmetry breast 5pt likert surgeon2 PCH2_scars Rate scars breast 5pt likert surgeon2 PCH2_nipple Rate nipple breast 5pt likert surgeon2 PCH2_score Mean score breast satisfaction surgeon2 PCH3_volume Rate volume breast 5pt likert surgeon3 PCH3_shape Rate shape breast 5pt likert surgeon3 PCH3_symmetry Rate symmetry breast 5pt likert surgeon3 PCH3_scars Rate scars breast 5pt likert surgeon3 PCH3_nipple Rate nipple breast 5pt likert surgeon3 PCH3_score Mean score breast satisfaction surgeon3 PCH4_volume Rate volume breast 5pt likert surgeon4 PCH4_shape Rate shape breast 5pt likert surgeon4 PCH4_symmetry Rate symmetry breast 5pt likert surgeon4 PCH4_scars Rate scars breast 5pt likert surgeon4 PCH4_nipple Rate nipple breast 5pt likert surgeon4 PCH4_score Mean score breast satisfaction surgeon4 PCH5_volume Rate volume breast 5pt likert surgeon5 PCH5_shape Rate shape breast 5pt likert surgeon5 PCH5_symmetry Rate symmetry breast 5pt likert surgeon5 PCH5_scars Rate scars breast 5pt likert surgeon5 PCH5_nipple Rate nipple breast 5pt likert surgeon5 PCH5_score Mean score breast satisfaction surgeon5 Mam1_volume Rate volume breast 5pt likert mother1 Mam1_shape Rate shape breast 5pt likert mother1 Mam1_symmetry Rate symmetry breast 5pt likert mother1 Mam1_scars Rate scars breast 5pt likert mother1 Mam1_nipple Rate nipple breast 5pt likert mother1 Mam1_score Mean score breast satisfaction mother1 Mam2_volume Rate volume breast 5pt likert mother2 Mam2_shape Rate shape breast 5pt likert mother2 Mam2_symmetry Rate symmetry breast 5pt likert mother2 Mam2_scars Rate scars breast 5pt likert mother2 Mam2_nipple Rate nipple breast 5pt likert mother2 Mam2_score Mean score breast satisfaction mother2 Mam3_volume Rate volume breast 5pt likert mother3 Mam3_shape Rate shape breast 5pt likert mother3 Mam3_symmetry Rate symmetry breast 5pt likert mother3 Mam3_scars Rate scars breast 5pt likert mother3 Mam3_nipple Rate nipple breast 5pt likert mother3 Mam3_score Mean score breast satisfaction mother3 @source data-raw/R/breast.R","code":""},{"path":"/reference/CIagreement-deprecated.html","id":null,"dir":"Reference","previous_headings":"","what":"Confidence interval around the (specific) agreement — CIagreement-deprecated","title":"Confidence interval around the (specific) agreement — CIagreement-deprecated","text":"confidence interval estimated around proportion agreement 2 raters. cat1 defined specific agreement calculated. cat1 = NULL overall agreement calculated. overall agreement specific agreement number likert categories 2, confidence interval obtained formula (Fleis correction values close 0 1 continuity correction end interval). number categories larger 2, bootstrapped confidence interval obtained.","code":""},{"path":"/reference/CIagreement-deprecated.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Confidence interval around the (specific) agreement — CIagreement-deprecated","text":"","code":"CIagreement(data, interval=0.95, cat1=NULL, cat2=NULL,m=NULL,n=NULL,b=1000)"},{"path":"/reference/CIagreement-deprecated.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Confidence interval around the (specific) agreement — CIagreement-deprecated","text":"data data.frame table cat1 character indicating category specific agreement obtained. cat2 character indicating category specific agreement compared, left empty categories used. interval Confidence level; default 0.95. m number categories n sample size b number boostrap iterations","code":""},{"path":"/reference/CIagreement-deprecated.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Confidence interval around the (specific) agreement — CIagreement-deprecated","text":"vector giving lower upper confidence limit around probability specific agreement.","code":""},{"path":[]},{"path":"/reference/CIbootagreement.html","id":null,"dir":"Reference","previous_headings":"","what":"Bootstrapped confidence interval around the Agreement — CIbootagreement","title":"Bootstrapped confidence interval around the Agreement — CIbootagreement","text":"confidence interval estimated around proportion agreement 2 raters.","code":""},{"path":"/reference/CIbootagreement.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Bootstrapped confidence interval around the Agreement — CIbootagreement","text":"","code":"CIbootagreement(data, cat1 = NULL, cat2 = NULL, b = 1000, alpha = 0.05)"},{"path":"/reference/CIbootagreement.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Bootstrapped confidence interval around the Agreement — CIbootagreement","text":"data data.frame table cat1 character indicating category specific agreement obtained. cat2 character indicating category specific agreement compared, left empty categories used. b Number bootstrap iterations. alpha Confidence level; default 0.95.","code":""},{"path":"/reference/CIbootagreement.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Bootstrapped confidence interval around the Agreement — CIbootagreement","text":"vector giving lower upper confidence limit around probability.","code":""},{"path":"/reference/CIbootagreement.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Bootstrapped confidence interval around the Agreement — CIbootagreement","text":"","code":"df <- data.frame(r1=factor(c(1,0,1,0,0,1,1,0,0,0,1,1,0,1,1)),                  r2=factor(c(1,1,1,1,0,1,1,0,0,0,1,1,0,1,0)),                  r3=factor(c(1,1,1,0,0,0,1,1,1,0,0,1,0,1,1)),                  r4=factor(c(1,1,1,1,1,1,1,1,1,1,1,1,1,1,1))) CIbootagreement(data=df) #>                 BCIlow.2.5% agreement.overall agreement  #>                   0.5111111                   0.6333333  #>               BCIhigh.97.5%  #>                   0.7666667"},{"path":"/reference/conditional.agreement.html","id":null,"dir":"Reference","previous_headings":"","what":"Conditional agreement for more than 2 categories — conditional.agreement","title":"Conditional agreement for more than 2 categories — conditional.agreement","text":"Conditional agreement two categories (averages discordant cells correct random rater combinations). INCLUDE FORMULAS.","code":""},{"path":"/reference/conditional.agreement.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Conditional agreement for more than 2 categories — conditional.agreement","text":"","code":"conditional.agreement(data, ...)"},{"path":"/reference/conditional.agreement.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Conditional agreement for more than 2 categories — conditional.agreement","text":"data data matrix table equal number columns rows. ... options sumtable","code":""},{"path":"/reference/conditional.agreement.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Conditional agreement for more than 2 categories — conditional.agreement","text":"conditionaltable table conditional agreement proportions. diagonal specific agreement proportions category displayed.","code":""},{"path":"/reference/conditional.agreement.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Conditional agreement for more than 2 categories — conditional.agreement","text":"","code":"df <- data.frame(r1=factor(c(1,2,2,0,3,3,1,0,3,0,2,2,0,3,1)),                  r2=factor(c(1,1,1,0,3,3,1,0,1,0,2,2,0,2,1)),                  r3=factor(c(1,1,1,3,3,2,1,0,1,0,2,2,0,3,1)),                  r4=factor(c(1,2,1,0,3,3,1,0,3,0,2,2,0,2,1))) conditional.agreement(df) #>   prevalence proportion     0     1     2     3 #> 0       22.5  0.2500000 0.933 0.000 0.000 0.067 #> 1       28.5  0.3166667 0.000 0.807 0.123 0.070 #> 2       21.0  0.2333333 0.000 0.167 0.667 0.167 #> 3       18.0  0.2000000 0.083 0.111 0.194 0.611"},{"path":"/reference/diagnoses.html","id":null,"dir":"Reference","previous_headings":"","what":"diagnoses — diagnoses","title":"diagnoses — diagnoses","text":"nominal data example use data set used paper Fleis (1971). data patients diagnosed 5 categories: Depression, Personality Disorder, Schizophrenia, Neurosis, six raters.","code":""},{"path":"/reference/diagnoses.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"diagnoses — diagnoses","text":"","code":"diagnoses"},{"path":"/reference/diagnoses.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"diagnoses — diagnoses","text":"data frame 30 rows 6 variables: rater5 diagnoses rater 5 rater1 diagnoses rater 1 rater3 diagnoses rater 3 rater2 diagnoses rater 2 rater6 diagnoses rater 6 rater4 diagnoses rater 4","code":""},{"path":"/reference/diagnoses.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"diagnoses — diagnoses","text":"data-raw/R/diagnoses.R","code":""},{"path":"/reference/icc.html","id":null,"dir":"Reference","previous_headings":"","what":"Intra class correlation for rater reliability — icc","title":"Intra class correlation for rater reliability — icc","text":"Intra class correlation rater reliability","code":""},{"path":"/reference/icc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Intra class correlation for rater reliability — icc","text":"","code":"icc(   data,   method = c(\"oneway\", \"agreement\", \"consistency\"),   cols = colnames(data),   sem = TRUE,   confint = TRUE,   alpha = 0.05,   var = FALSE,   onemodel = FALSE )"},{"path":"/reference/icc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Intra class correlation for rater reliability — icc","text":"data data.frame repeated measures observations columns rated subjects rows method type ICC returned, options : `c(\"oneway\", \"agreement\", \"consistency\")`, default returns . cols column names used repeated measures wide format, default uses `cols = colnames(data)` sem logical vector standard error measurement returned. confint logical vector confidence interval ICC returned. alpha confidence level required, default `alpha = 0.05`. var logical indicator variance estimates returned. onemodel logical indicator ICC's computed one model increase computation time, defalt `onemodel = FALSE`.","code":""},{"path":"/reference/icc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Intra class correlation for rater reliability — icc","text":"matrix relevant output","code":""},{"path":[]},{"path":"/reference/icc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Intra class correlation for rater reliability — icc","text":"","code":"mam <- breast[,c(\"Mam1_score\",\"Mam2_score\", \"Mam3_score\")] icc(data = mam, confint = TRUE, var = TRUE) #>                   icc     lower     upper       sem var_level1 var_level2 #> oneway      0.6001478 0.4493754 0.7309390 1.1515241   1.990237         NA #> agreement   0.5698257 0.4137129 0.7079019 1.1919337   1.881923  0.4443499 #> consistency 0.6558989 0.5162467 0.7724701 0.9899547   1.868020         NA #>             var_Residual #> oneway         1.3260076 #> agreement      0.9763561 #> consistency    0.9800104 pch <- breast[,c(\"PCH1_score\", \"PCH2_score\",\"PCH3_score\", \"PCH4_score\",\"PCH5_score\")] icc(data = pch) #>                   icc     lower     upper       sem #> oneway      0.7615871 0.6710817 0.8403886 0.8591071 #> agreement   0.7593693 0.6682981 0.8387870 0.8611481 #> consistency 0.7711953 0.6829366 0.8473933 0.8317713 icc(data = pch, confint = FALSE, var = TRUE) #>                   icc       sem var_level1 var_level2 var_Residual #> oneway      0.7615871 0.8591071   2.357677         NA    0.7380650 #> agreement   0.7593693 0.8611481   2.340225 0.05026114    0.6913149 #> consistency 0.7711953 0.8317713   2.331886         NA    0.6918435"},{"path":"/reference/icc_agreement.html","id":null,"dir":"Reference","previous_headings":"","what":"ICC agreement — icc_agreement","title":"ICC agreement — icc_agreement","text":"intraclass correlations (ICC) agreement rater reliability using variance estimates linear mixed model. function returns icc, standard error measurment (sem) confidence intervals icc.","code":""},{"path":"/reference/icc_agreement.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"ICC agreement — icc_agreement","text":"","code":"icc_agreement(   data,   cols = colnames(data),   alpha = 0.05,   CI_estimator = \"exact\" )"},{"path":"/reference/icc_agreement.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"ICC agreement — icc_agreement","text":"data data.frame column observer/rater row per rated subject. cols character vector column names used observers. Default `cols = colnames(data)`. alpha confidence interval level, default `alpha = 0.05`. CI_estimator character \"exact\" \"approx\" switch using exact F-test approximated estimate. latter accounts three independent variance components. Default `CI_estimator = \"exact\"`.","code":""},{"path":"/reference/icc_agreement.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"ICC agreement — icc_agreement","text":"list","code":""},{"path":"/reference/icc_agreement.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"ICC agreement — icc_agreement","text":"icc type agreement variance subjects divided sum subject variance, rater variance residual variance. ICC agreement generalizes raters within population (Shrout & Fleiss, 1979). `varcomp()` function used compute variances. variance components estimated `lmer` model random slope subjects well raters. sem square root sum rater variance error variance. confidence intervals approximated account three independent variance components, defined Satterthwaite (1946) & Fleiss Shrout (1978).","code":""},{"path":"/reference/icc_agreement.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"ICC agreement — icc_agreement","text":"Fleiss, J. L., & Shrout, P. E. Approximate interval estimation certain intraclass correlation coefficient. Psychometrika, 1978, 43, 259-262. Satterthwaite, F. E. approximate distribution estimates variance components. Biometrics, 1946, 2, 110-114. Shrout, P.E. & Fleiss, J.L. (1979) Intraclass Correlations: Uses Assessing Rater Reliability. Psychological Bulletin, 87(2), 420-428.","code":""},{"path":"/reference/icc_agreement.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"ICC agreement — icc_agreement","text":"Iris Eekhout","code":""},{"path":"/reference/icc_consistency.html","id":null,"dir":"Reference","previous_headings":"","what":"ICC consistency — icc_consistency","title":"ICC consistency — icc_consistency","text":"intraclass correlations (ICC) consistency rater reliability using variance estimates linear mixed model. function returns ICC, standard error measurment (sem) confidence intervals ICC.","code":""},{"path":"/reference/icc_consistency.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"ICC consistency — icc_consistency","text":"","code":"icc_consistency(data, cols = colnames(data), alpha = 0.05, twoway = FALSE)"},{"path":"/reference/icc_consistency.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"ICC consistency — icc_consistency","text":"data data.frame column observer/rater row per rated subject. cols character vector column names used observers. Default `cols = colnames(data)`. alpha confidence interval level, default `alpha = 0.05`. twoway logical indicator variance components estimated two-way model default: `twoway = FALSE`.","code":""},{"path":"/reference/icc_consistency.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"ICC consistency — icc_consistency","text":"list","code":""},{"path":"/reference/icc_consistency.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"ICC consistency — icc_consistency","text":"ICC type consistency variance subjects divided sum subject variance residual variance. subject variance error variance adjusted fixed rater effect, accordingly rater variance used calculate ICC. ICC consistency generalizes fixed set raters data (Shrout & Fleiss, 1979). `icc_model()` function used compute variances. `lmer` model random slope subjects well raters. sem square root error variance. confidence computed exact F method. F = (k * subject variance + error variance)/ error variance, df1 = n - 1 df2 = (n - 1) * (k - 1) (Shrout & Fleiss, 1979).","code":""},{"path":"/reference/icc_consistency.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"ICC consistency — icc_consistency","text":"Fleiss, J. L., & Shrout, P. E. Approximate interval estimation certain intraclass correlation coefficient. Psychometrika, 1978, 43, 259-262.","code":""},{"path":"/reference/icc_consistency.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"ICC consistency — icc_consistency","text":"Iris Eekhout","code":""},{"path":"/reference/icc_oneway.html","id":null,"dir":"Reference","previous_headings":"","what":"ICC oneway — icc_oneway","title":"ICC oneway — icc_oneway","text":"function computes one-way intraclass correlations (ICC), corresponding standard error measurement, sem, confidence intervals, using variance estimates linear mixed model. See details information.","code":""},{"path":"/reference/icc_oneway.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"ICC oneway — icc_oneway","text":"","code":"icc_oneway(data, cols = colnames(data), alpha = 0.05, twoway = FALSE)"},{"path":"/reference/icc_oneway.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"ICC oneway — icc_oneway","text":"data data.frame column observer/rater row per rated subject. cols character vector column names used observers. Default `cols = colnames(data)`. alpha confidence interval level, default `alpha = 0.05`. twoway logical indicator variance components estimated two-way model default: `twoway = FALSE`.","code":""},{"path":"/reference/icc_oneway.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"ICC oneway — icc_oneway","text":"`list` parameter estimates.","code":""},{"path":"/reference/icc_oneway.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"ICC oneway — icc_oneway","text":"ICC type oneway variance subjects divided sum subject variance residual variance (total variance oneway model. subject rated different set raters, randomly selected larger population judges (Shrout & Fleiss, 1979). `icc_oneway()` uses `varcomp()` function compute variances. Theses variances estimated `lmer` model random slope subjects. `twoway = TRUE` level raters estimated well rater variance used ICC oneway subtracted sum subject variance raters, averaged. error variance computed sum residual variance rater variance. Accordingly, rater variance part error variance. standard #' error measurement square root error variance. confidence intervals computed exact F method. F = (k * subject variance + error variance)/ error variance, df1 = n - 1 df2 = n * (k - 1) (Shrout & Fleiss, 1979).","code":""},{"path":"/reference/icc_oneway.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"ICC oneway — icc_oneway","text":"Shrout, P.E. & Fleiss, J.L. (1979) Intraclass Correlations: Uses Assessing Rater Reliability. Psychological Bulletin, 87(2), 420-428.","code":""},{"path":"/reference/icc_oneway.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"ICC oneway — icc_oneway","text":"Iris Eekhout","code":""},{"path":"/reference/kappa.html","id":null,"dir":"Reference","previous_headings":"","what":"Kappa for agreement with multiple raters — kappa","title":"Kappa for agreement with multiple raters — kappa","text":"Cohen's kappa weighed kappa multiple raters, adapted `psych::cohen.kappa` function (Revelle, 2020). Light's method used combine scores multiple raters.","code":""},{"path":"/reference/kappa.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Kappa for agreement with multiple raters — kappa","text":"","code":"kappa(   data,   weight = NULL,   confint = FALSE,   alpha = 0.05,   k = NULL,   n = NULL,   ... )"},{"path":"/reference/kappa.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Kappa for agreement with multiple raters — kappa","text":"data `data.frame` table equal number columns rows. `data.frame` contains scores rater column. weight matrix weights weighed kappa. confint Logical indicator confidence interval alpha Confidence interval level, default = 0.05. k number raters; default `k = ncol(data)`. n sample size; default `n = nrow(data)`. ... options sumtable `.data.frame(data)`","code":""},{"path":"/reference/kappa.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Kappa for agreement with multiple raters — kappa","text":"vector","code":""},{"path":"/reference/kappa.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Kappa for agreement with multiple raters — kappa","text":"Revelle, W. (2020) psych: Procedures Personality Psychological Research, Northwestern University, Evanston, Illinois, USA, https://CRAN.R-project.org/package=psych Version = 2.0.12,. Light, R. J. (1971) Measures response agreement qualitative data: generalizations alternatives, Psychological Bulletin, 76, 365-377.","code":""},{"path":"/reference/kappa.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Kappa for agreement with multiple raters — kappa","text":"","code":"df <- data.frame(r1=factor(c(1,0,1,0,0,1,1,0,0,0,1,1,0,1,1)),                  r2=factor(c(1,1,1,1,0,1,1,0,0,0,1,1,0,1,0)),                  r3=factor(c(1,1,1,0,0,0,1,1,1,0,0,1,0,1,1)),                  r4=factor(c(1,1,1,1,1,1,1,1,1,1,1,1,1,1,1))) table <- sumtable(df=df, ratings=c(\"r1\", \"r2\", \"r3\", \"r4\"), levels=c(\"0\",\"1\")) kappa(df) #>          kappa weighted kappa  #>      0.2028986      0.2028986  kappa(table) #>          kappa weighted kappa  #>      0.2028986      0.2028986   df <- data.frame(r1=factor(c(1,2,2,0,3,3,1,0,3,0,2,2,0,3,1)),                  r2=factor(c(1,1,1,0,3,3,1,0,1,0,2,2,0,2,1)),                  r3=factor(c(1,1,1,3,3,2,1,0,1,0,2,2,0,3,1)),                  r4=factor(c(1,2,1,0,3,3,1,0,3,0,2,2,0,2,1))) table <- sumtable(df=df, ratings=c(\"r1\", \"r2\", \"r3\", \"r4\"), levels=c(\"0\",\"1\", \"2\", \"3\")) kappa(df) #>          kappa weighted kappa  #>      0.6858639      0.7213395  kappa(table) #>          kappa weighted kappa  #>      0.6858639      0.7213395  kappa(df, confint = TRUE) #>                    kappa     lower     upper #> kappa          0.6858639 0.5691753 0.8025525 #> weighted kappa 0.7213395 0.5689155 0.8737636 kappa(table) #>          kappa weighted kappa  #>      0.6858639      0.7213395"},{"path":"/reference/n_icc.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample size for ICC — n_icc","title":"Sample size for ICC — n_icc","text":"Sample size ICC","code":""},{"path":"/reference/n_icc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample size for ICC — n_icc","text":"","code":"n_icc(beta = 0.8, alpha = 0.05, k = 3, icc, icc_lower)"},{"path":"/reference/n_icc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sample size for ICC — n_icc","text":"beta power level, default beta = 0.8, also called assurance probability. alpha confidence level, default alpha = 0.05 k number raters, default k = 3 icc reliability coefficient icc_lower lower limit reliability coefficient icc","code":""},{"path":"/reference/n_icc.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Sample size for ICC — n_icc","text":"Calculate sample size achieving certain lower limit confidence interval derived F procedure. method developed ICC type oneway.","code":""},{"path":"/reference/n_icc.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Sample size for ICC — n_icc","text":"Zou, G.Y. (2012) Sample size formulas estimating intraclass correlation coefficients precision assurance. Statistics medicine, 31, 3971-3981.","code":""},{"path":"/reference/n_icc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sample size for ICC — n_icc","text":"","code":"n_icc(icc = 0.7, icc_lower = 0.6, k = 4) #> [1] 109.6927 n_icc(icc = 0.7, icc_lower = 0.6, k = 2) #> [1] 204.8471 n_icc(icc = 0.7, icc_lower = 0.6, k = 3) #> [1] 133.1105"},{"path":"/reference/positive.agreement-deprecated.html","id":null,"dir":"Reference","previous_headings":"","what":"positive agreement-deprecated — positive.agreement-deprecated","title":"positive agreement-deprecated — positive.agreement-deprecated","text":"function obtain positive negative agreement 2 raters categories dichotomous.","code":""},{"path":"/reference/positive.agreement-deprecated.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"positive agreement-deprecated — positive.agreement-deprecated","text":"","code":"positive.agreement(data, specific, ...)"},{"path":"/reference/positive.agreement-deprecated.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"positive agreement-deprecated — positive.agreement-deprecated","text":"data data matrix table equal number columns rows. data frame contains scores rater column. specific character vector indicating whether \"positive\" \"negative\" agreements obtained. ... optoins sumtable.","code":""},{"path":"/reference/positive.agreement-deprecated.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"positive agreement-deprecated — positive.agreement-deprecated","text":"S3 object containing proportion positive (negative) agreement.","code":""},{"path":[]},{"path":"/reference/simoutput.html","id":null,"dir":"Reference","previous_headings":"","what":"simoutput — simoutput","title":"simoutput — simoutput","text":"Output results simulation different icc methods various conditions investigate sample size number raters requirements ICC SEM calculations.","code":""},{"path":"/reference/simoutput.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"simoutput — simoutput","text":"","code":"simoutput"},{"path":"/reference/simoutput.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"simoutput — simoutput","text":"data frame 2280 rows 22 variables: n condition parameter: sample size cor condition parameter: raw correlation raters k condition parameter: number raters variance condition parameter: variance patients deviation condition parameter: k raters systematic deviation method condition parameter: icc method set condition parameter: simultion iteration (averaged) icc output parameter: average icc lower output parameter: average lower bound CI icc upper output parameter: average upper bound CI icc sem output parameter: average sem varpat output parameter: variance patients varobs output parameter: variance raters varerr output parameter: residual variance Ticc empirical population parameter: icc Tsem empirical population parameter: sem bias_icc result parameter: average bias icc bias_sem result parameter: average bias sem mse_icc result parameter: mean squared error icc mse_sem result parameter: mean squared error sem cov_icc result parameter: coverage CI icc width_icc result parameter: width CI icc width_sem result parameter: width CI sem","code":""},{"path":"/reference/simoutput.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"simoutput — simoutput","text":"data-raw/R/simoutput.R","code":""},{"path":"/reference/specific.agreement-deprecated.html","id":null,"dir":"Reference","previous_headings":"","what":"Specific agreement-deprecated — specific.agreement-deprecated","title":"Specific agreement-deprecated — specific.agreement-deprecated","text":"specific agreement (averages discordant cells correct random rater combinations). INCLUDE FORMULAS. 2 categories, equal postive/negative agreement. two categories, one can either look agreement one category versus others, example satisfied verus rest one category versus one specific categorie, example satisfies versus satisfied.","code":""},{"path":"/reference/specific.agreement-deprecated.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Specific agreement-deprecated — specific.agreement-deprecated","text":"","code":"specific.agreement(data, cat1, cat2, ...)"},{"path":"/reference/specific.agreement-deprecated.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Specific agreement-deprecated — specific.agreement-deprecated","text":"data data matrix table equal number columns rows. data frame contains scores rater column. cat1 character indicating category specific agreement obtained. cat2 character indicating category specific agreement compared, left empty categories used. ... options sumtable","code":""},{"path":"/reference/specific.agreement-deprecated.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Specific agreement-deprecated — specific.agreement-deprecated","text":"S3 object containing proportion specific agreement.","code":""},{"path":[]},{"path":"/reference/sumtable.html","id":null,"dir":"Reference","previous_headings":"","what":"Summed Table — sumtable","title":"Summed Table — sumtable","text":"function can used calculate sum tables combination raters. output table can used estimate agreement statistics two raters. First crosstable made combination raters. results 2*(m-1) tables, m number raters. tables summed one table.","code":""},{"path":"/reference/sumtable.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summed Table — sumtable","text":"","code":"sumtable(df, ratings = NULL, levels = NULL, offdiag = NULL)"},{"path":"/reference/sumtable.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summed Table — sumtable","text":"df input data frame contains scores rater column ratings character vector contains names factor variables need used ratings levels character vector contains levels factors. offdiag logical parameter indicating diagonal means used, default TRUE two raters","code":""},{"path":"/reference/sumtable.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summed Table — sumtable","text":"Returns contingency table, object class \"table\", array integer values.","code":""},{"path":"/reference/sumtable.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summed Table — sumtable","text":"","code":"df <- data.frame(r1=factor(c(1,0,1,0,0,1,1,0,0,0,1,1,0,1,1)),                  r2=factor(c(1,1,1,1,0,1,1,0,0,0,1,1,0,1,0)),                  r3=factor(c(1,1,1,0,0,0,1,1,1,0,0,1,0,1,1)),                  r4=factor(c(1,1,1,1,1,1,1,1,1,1,1,1,1,1,1))) sumtable(df=df, ratings=c(\"r1\", \"r2\", \"r3\", \"r4\"), levels=c(\"0\",\"1\")) #>    0  1 #> 0 12 27 #> 1  6 45  df <- data.frame(r1=factor(c(1,2,2,0,3,3,1,0,3,0,2,2,0,3,1)),                  r2=factor(c(1,1,1,0,3,3,1,0,1,0,2,2,0,2,1)),                  r3=factor(c(1,1,1,3,3,2,1,0,1,0,2,2,0,3,1)),                  r4=factor(c(1,2,1,0,3,3,1,0,3,0,2,2,0,2,1))) sumtable(df=df, ratings=c(\"r1\", \"r2\", \"r3\", \"r4\"), levels=c(\"0\",\"1\", \"2\", \"3\")) #>      0    1    2    3 #> 0 21.0  0.0  0.0  1.5 #> 1  0.0 23.0  3.5  2.0 #> 2  0.0  3.5 14.0  3.5 #> 3  1.5  2.0  3.5 11.0"},{"path":"/reference/varcomp.html","id":null,"dir":"Reference","previous_headings":"","what":"Variance components — varcomp","title":"Variance components — varcomp","text":"Variance components","code":""},{"path":"/reference/varcomp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Variance components — varcomp","text":"","code":"varcomp(formula, data)"},{"path":"/reference/varcomp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Variance components — varcomp","text":"formula two-sided linear formula object describing fixed-effects random-effects part model, response left ~ operator terms, separated + operators, right. Random-effects terms distinguished vertical bars (|) separating expressions design matrices grouping factors. Two vertical bars (||) can used specify multiple uncorrelated random effects grouping variable. (way implemented, ||-syntax works design matrices containing numeric (continuous) predictors; fit models independent categorical effects, see dummy lmer_alt function afex package.) data data.frame containing variables named `formula`.","code":""},{"path":"/reference/varcomp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Variance components — varcomp","text":"data.frame variance components rows","code":""},{"path":"/reference/varcomp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Variance components — varcomp","text":"","code":"library(dplyr) #>  #> Attaching package: 'dplyr' #> The following objects are masked from 'package:stats': #>  #>     filter, lag #> The following objects are masked from 'package:base': #>  #>     intersect, setdiff, setequal, union pch <- breast[,c(\"PCH1_score\", \"PCH2_score\",\"PCH3_score\", \"PCH4_score\",\"PCH5_score\")] %>% mutate(id = 1:nrow(breast)) pch_l <- tidyr::pivot_longer(pch, cols= PCH1_score:PCH5_score, names_to = \"rater\", values_to = \"score\") varcomp(formula = score ~ (1|id) + (1|rater),  data = pch_l) #>               grp       vcov #> id             id 2.34022480 #> rater       rater 0.05026114 #> Residual Residual 0.69131486"},{"path":"/reference/weighted.agreement.html","id":null,"dir":"Reference","previous_headings":"","what":"Weighted agreement — weighted.agreement","title":"Weighted agreement — weighted.agreement","text":"agreement 2 raters may one category , category weighted 1 default. relevant ordinal rating scales 2 Likert categories.","code":""},{"path":"/reference/weighted.agreement.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Weighted agreement — weighted.agreement","text":"","code":"weighted.agreement(data, weight = 1, ...)"},{"path":"/reference/weighted.agreement.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Weighted agreement — weighted.agreement","text":"data data matrix table equal number columns rows. data frame contains scores rater column. weight weight one-category, default weight = 1 ... options sumtable","code":""},{"path":"/reference/weighted.agreement.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Weighted agreement — weighted.agreement","text":"S3 object containing proportion agreement.","code":""},{"path":"/reference/weighted.agreement.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Weighted agreement — weighted.agreement","text":"","code":"df <- data.frame(r1=factor(c(1,2,2,0,3,3,1,0,3,0,2,2,0,3,1)),                  r2=factor(c(1,1,1,0,3,3,1,0,1,0,2,2,0,2,1)),                  r3=factor(c(1,1,1,3,3,2,1,0,1,0,2,2,0,3,1)),                  r4=factor(c(1,2,1,0,3,3,1,0,3,0,2,2,0,2,1))) table <- sumtable(df=df, ratings=c(\"r1\", \"r2\", \"r3\", \"r4\"), levels=c(\"0\",\"1\", \"2\", \"3\")) weighted.agreement(table) #> [1] 0.9222222"}]
